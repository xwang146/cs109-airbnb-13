{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Final Project\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors:** W. Pan, P. Protopapas, K. Rader<br>\n",
    "**Members: ** Shawn Pan, Xinyuan (Amy) Wang, Ming-long Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark ##\n",
    "\n",
    "- Code work in progress by Ming-Long\n",
    "- Based on the BaselineFinal\n",
    "- Tried log(price) - show QQ-plot\n",
    "- Tried neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import xgboost\n",
    "from itertools import combinations\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'host_since' 'zipcode' 'latitude' 'longitude' 'property_type'\n",
      " 'room_type' 'accommodates' 'bathrooms' 'bedrooms' 'beds' 'bed_type'\n",
      " 'guests_included' 'minimum_nights' 'maximum_nights' 'availability_30'\n",
      " 'availability_60' 'availability_90' 'availability_365' 'number_of_reviews'\n",
      " 'first_review' 'last_review' 'review_scores_rating'\n",
      " 'review_scores_accuracy' 'review_scores_cleanliness'\n",
      " 'review_scores_checkin' 'review_scores_communication'\n",
      " 'review_scores_location' 'review_scores_value' 'host_listing_count'\n",
      " 'price']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_since</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>host_listing_count</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1069266</td>\n",
       "      <td>1926</td>\n",
       "      <td>10022.0</td>\n",
       "      <td>40.756852</td>\n",
       "      <td>-73.964754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1846722</td>\n",
       "      <td>1625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.830599</td>\n",
       "      <td>-73.941014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2554.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2061725</td>\n",
       "      <td>1831</td>\n",
       "      <td>11221.0</td>\n",
       "      <td>40.692189</td>\n",
       "      <td>-73.924120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2554.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44974</td>\n",
       "      <td>953</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>40.734751</td>\n",
       "      <td>-74.002592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4701675</td>\n",
       "      <td>2479</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>40.745282</td>\n",
       "      <td>-73.997836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2533.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  host_since  zipcode   latitude  longitude  property_type  \\\n",
       "0  1069266        1926  10022.0  40.756852 -73.964754              0   \n",
       "1  1846722        1625      NaN  40.830599 -73.941014              0   \n",
       "2  2061725        1831  11221.0  40.692189 -73.924120              0   \n",
       "3    44974         953  10011.0  40.734751 -74.002592              0   \n",
       "4  4701675        2479  10011.0  40.745282 -73.997836              0   \n",
       "\n",
       "   room_type  accommodates  bathrooms  bedrooms  ...    last_review  \\\n",
       "0          0             2        1.0       1.0  ...         2542.0   \n",
       "1          0            10        1.0       3.0  ...         2554.0   \n",
       "2          1             2        1.0       1.0  ...         2554.0   \n",
       "3          0             2        1.0       1.0  ...         2494.0   \n",
       "4          0             2        1.0       1.0  ...         2533.0   \n",
       "\n",
       "   review_scores_rating  review_scores_accuracy  review_scores_cleanliness  \\\n",
       "0                  86.0                     9.0                        7.0   \n",
       "1                  85.0                     8.0                        8.0   \n",
       "2                  98.0                    10.0                       10.0   \n",
       "3                  96.0                    10.0                        9.0   \n",
       "4                 100.0                    10.0                       10.0   \n",
       "\n",
       "   review_scores_checkin  review_scores_communication  review_scores_location  \\\n",
       "0                    9.0                          9.0                    10.0   \n",
       "1                    9.0                          8.0                     7.0   \n",
       "2                   10.0                         10.0                     9.0   \n",
       "3                   10.0                         10.0                    10.0   \n",
       "4                   10.0                         10.0                    10.0   \n",
       "\n",
       "   review_scores_value  host_listing_count  price  \n",
       "0                  9.0                   1    160  \n",
       "1                  8.0                   2    105  \n",
       "2                 10.0                   4     58  \n",
       "3                  9.0                   1    185  \n",
       "4                 10.0                   1    195  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data\n",
    "df = pd.read_csv('listings_clean.csv')\n",
    "print(df.columns.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27392, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 5% samples from smallest zipcode clusters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining data proportion: 0.94976635514\n",
      "(26016, 31)\n"
     ]
    }
   ],
   "source": [
    "# remove small zipcode clusters, with 95% data left\n",
    "# count each zipcode entries\n",
    "nb_counts = Counter(df['zipcode'])\n",
    "tdf = pd.DataFrame.from_dict(nb_counts, orient='index').sort_values(by=0)\n",
    "# select clusters with size >= 50\n",
    "tdf1 = tdf[tdf.values>=50]\n",
    "print 'Remaining data proportion: ' + str(float(sum(tdf1.values))/df.shape[0])\n",
    "# get zipcode clusters\n",
    "zipcode_included = tdf1.index\n",
    "\n",
    "df1 = df.loc[df['zipcode'].isin(zipcode_included)]\n",
    "print df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>host_listing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10022.0</td>\n",
       "      <td>40.756852</td>\n",
       "      <td>-73.964754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>86.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11221.0</td>\n",
       "      <td>40.692189</td>\n",
       "      <td>-73.924120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10011.0</td>\n",
       "      <td>40.734751</td>\n",
       "      <td>-74.002592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10011.0</td>\n",
       "      <td>40.745282</td>\n",
       "      <td>-73.997836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11231.0</td>\n",
       "      <td>40.679060</td>\n",
       "      <td>-73.994730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode   latitude  longitude  property_type  room_type  accommodates  \\\n",
       "0  10022.0  40.756852 -73.964754              0          0             2   \n",
       "2  11221.0  40.692189 -73.924120              0          1             2   \n",
       "3  10011.0  40.734751 -74.002592              0          0             2   \n",
       "4  10011.0  40.745282 -73.997836              0          0             2   \n",
       "5  11231.0  40.679060 -73.994730              0          0             6   \n",
       "\n",
       "   bathrooms  bedrooms  beds  bed_type  number_of_reviews  \\\n",
       "0        1.0       1.0   1.0         0                 62   \n",
       "2        1.0       1.0   2.0         0                 35   \n",
       "3        1.0       1.0   1.0         0                 26   \n",
       "4        1.0       1.0   2.0         0                  1   \n",
       "5        1.0       2.0   3.0         0                 16   \n",
       "\n",
       "   review_scores_rating  review_scores_accuracy  review_scores_cleanliness  \\\n",
       "0                  86.0                     9.0                        7.0   \n",
       "2                  98.0                    10.0                       10.0   \n",
       "3                  96.0                    10.0                        9.0   \n",
       "4                 100.0                    10.0                       10.0   \n",
       "5                  96.0                    10.0                        9.0   \n",
       "\n",
       "   review_scores_checkin  review_scores_communication  review_scores_location  \\\n",
       "0                    9.0                          9.0                    10.0   \n",
       "2                   10.0                         10.0                     9.0   \n",
       "3                   10.0                         10.0                    10.0   \n",
       "4                   10.0                         10.0                    10.0   \n",
       "5                   10.0                          9.0                    10.0   \n",
       "\n",
       "   review_scores_value  host_listing_count  \n",
       "0                  9.0                   1  \n",
       "2                 10.0                   4  \n",
       "3                  9.0                   1  \n",
       "4                 10.0                   1  \n",
       "5                  9.0                   2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Extraction:\n",
    "#Use the features we decided last time\n",
    "features = ['zipcode', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', \n",
    "            'bathrooms', 'bedrooms', 'beds', 'bed_type', 'number_of_reviews', 'review_scores_rating',\n",
    "            'review_scores_accuracy', 'review_scores_cleanliness', \n",
    "            'review_scores_checkin', 'review_scores_communication', \n",
    "            'review_scores_location', 'review_scores_value', 'host_listing_count']\n",
    "\n",
    "df_x = df1[features]\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start imputing missing values. We fill in numerical values with the mean of its columns, fill in categorical values with most common value of its column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>host_listing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10022.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.756852</td>\n",
       "      <td>-73.964754</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>86.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11221.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.692189</td>\n",
       "      <td>-73.924120</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.734751</td>\n",
       "      <td>-74.002592</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.745282</td>\n",
       "      <td>-73.997836</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.679060</td>\n",
       "      <td>-73.994730</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode  property_type  room_type  bed_type   latitude  longitude  \\\n",
       "0  10022.0              0          0         0  40.756852 -73.964754   \n",
       "2  11221.0              0          1         0  40.692189 -73.924120   \n",
       "3  10011.0              0          0         0  40.734751 -74.002592   \n",
       "4  10011.0              0          0         0  40.745282 -73.997836   \n",
       "5  11231.0              0          0         0  40.679060 -73.994730   \n",
       "\n",
       "   accommodates  bathrooms  bedrooms  beds  number_of_reviews  \\\n",
       "0             2        1.0       1.0   1.0                 62   \n",
       "2             2        1.0       1.0   2.0                 35   \n",
       "3             2        1.0       1.0   1.0                 26   \n",
       "4             2        1.0       1.0   2.0                  1   \n",
       "5             6        1.0       2.0   3.0                 16   \n",
       "\n",
       "   review_scores_rating  review_scores_accuracy  review_scores_cleanliness  \\\n",
       "0                  86.0                     9.0                        7.0   \n",
       "2                  98.0                    10.0                       10.0   \n",
       "3                  96.0                    10.0                        9.0   \n",
       "4                 100.0                    10.0                       10.0   \n",
       "5                  96.0                    10.0                        9.0   \n",
       "\n",
       "   review_scores_checkin  review_scores_communication  review_scores_location  \\\n",
       "0                    9.0                          9.0                    10.0   \n",
       "2                   10.0                         10.0                     9.0   \n",
       "3                   10.0                         10.0                    10.0   \n",
       "4                   10.0                         10.0                    10.0   \n",
       "5                   10.0                          9.0                    10.0   \n",
       "\n",
       "   review_scores_value  host_listing_count  \n",
       "0                  9.0                   1  \n",
       "2                 10.0                   4  \n",
       "3                  9.0                   1  \n",
       "4                 10.0                   1  \n",
       "5                  9.0                   2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#categorical and numerical column names\n",
    "cate = ['zipcode', 'property_type', 'room_type', 'bed_type']\n",
    "nume = [c for c in df_x.columns.values if c not in cate]\n",
    "\n",
    "#fill categorical with mode, numerical with mean\n",
    "df_x_cate = df_x[cate].apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "df_x_nume = df_x[nume].apply(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "df_x = pd.concat([df_x_cate, df_x_nume], axis=1)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,  10.,   9.,   1.],\n",
       "       [  0.,   0.,   0., ...,   9.,  10.,   4.],\n",
       "       [  0.,   0.,   0., ...,  10.,   9.,   1.],\n",
       "       ..., \n",
       "       [  0.,   0.,   0., ...,   9.,   8.,  15.],\n",
       "       [  0.,   0.,   0., ...,   9.,  10.,   7.],\n",
       "       [  0.,   0.,   0., ...,  10.,  10.,   2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numpy array from data\n",
    "x = df_x.values\n",
    "\n",
    "# Apply one hot endcoing\n",
    "categorical = [(c in cate) for c in df_x.columns]\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical, sparse=False)  \n",
    "\n",
    "x = encoder.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26016, 103)\n",
      "(26016,)\n"
     ]
    }
   ],
   "source": [
    "print x.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11c8d9350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnkAAAJtCAYAAABKTmYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa518d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check normality of predictors in x_pca\n",
    "fig3, ax3 = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# Check y distribution\n",
    "ax3[0, 0].hist(y, bins = 32, facecolor = 'blue')\n",
    "ax3[0, 0].set_xlabel('y', fontsize=14)\n",
    "ax3[0, 0].set_ylabel('frequency', fontsize=14)\n",
    "ax3[0, 0].set_title('Var: ' + str(np.var(y)), fontsize=14)\n",
    "\n",
    "sm.qqplot(y,ax=ax3[0, 1], fit=True, line='45')\n",
    "ax3[0, 1].set_xlabel('normal quantile', fontsize=14)\n",
    "ax3[0, 1].set_ylabel('predictor quantile', fontsize=14)\n",
    "ax3[0, 1].set_title('Normal QQ-plot', fontsize=14)\n",
    "\n",
    "# Check log(y) distribution\n",
    "ax3[1, 0].hist(np.log(y), bins = 32, facecolor = 'blue')\n",
    "ax3[1, 0].set_xlabel('y', fontsize=14)\n",
    "ax3[1, 0].set_ylabel('frequency', fontsize=14)\n",
    "ax3[1, 0].set_title('Var: ' + str(np.var(y)), fontsize=14)\n",
    "\n",
    "sm.qqplot(np.log(y),ax=ax3[1, 1], fit=True, line='45')\n",
    "ax3[1, 1].set_xlabel('normal quantile', fontsize=14)\n",
    "ax3[1, 1].set_ylabel('predictor quantile', fontsize=14)\n",
    "ax3[1, 1].set_title('Normal QQ-plot', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform y with log to make it more symmetric\n",
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've already preprocessed data in both files. We could start build models. We split our training dataset into train data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_log, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (18211, 103)\n",
      "test data:  (7805, 103)\n"
     ]
    }
   ],
   "source": [
    "print 'train data: ', x_train.shape\n",
    "print 'test data: ', x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.2.1.\n",
      "The scikit-learn version is 0.17.1.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=103, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-106ecddeed38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f (%.2f) MSE\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0muninitialized_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0muninitialized_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(len(x_train),n_folds=10)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, nb_epoch=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(len(x_train),n_folds=10)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a deeper network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define R square score function\n",
    "def score(in_y_pred, in_y_act):\n",
    "    \n",
    "#     in_y_act = in_actual['y'].values\n",
    "#     in_y_pred = in_predict['y'].values\n",
    "    in_y_act_mean = in_y_act.mean()\n",
    "    in_y_pred_mean = in_y_pred.mean()\n",
    "    \n",
    "    # input in_predict are an input dataframe\n",
    "    RSS = np.multiply((in_y_act - in_y_pred), (in_y_act - in_y_pred)).sum()\n",
    "    TSS = np.multiply((in_y_act - in_y_act_mean), (in_y_act - in_y_act_mean)).sum()\n",
    "    #\n",
    "    R_square = 1 - (RSS / TSS)\n",
    "    \n",
    "    return R_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "x_std = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_std, y_log, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(103, input_dim=103, init='normal', activation='relu'))\n",
    "    model.add(Dense(50, init='normal', activation='relu'))\n",
    "    model.add(Dense(25, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasped time: 419.518140078\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "model_1=larger_model()\n",
    "model_1.fit(x_train, y_train, batch_size=10, nb_epoch=100, verbose=0)\n",
    "time_elapsed=time.time()-time_start\n",
    "print 'Elasped time: ' + str(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred=model_1.predict(x_train, batch_size=32, verbose=0)\n",
    "y_test_pred=model_1.predict(x_test, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18211,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759198976151\n"
     ]
    }
   ],
   "source": [
    "print score(np.reshape(y_train_pred,(y_train_pred.shape[0],)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650077017076\n"
     ]
    }
   ],
   "source": [
    "print score(np.reshape(y_test_pred,(y_test_pred.shape[0],)), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 0.17 (0.02) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using a deeper network\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, nb_epoch=5, batch_size=10, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(len(x_train),n_folds=10)\n",
    "results = cross_val_score(pipeline, x_train, y_train, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('mlp', <keras.wrappers.scikit_learn.KerasRegressor object at 0x12f2a1c50>)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for classification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=103, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18211/18211 [==============================] - 6s - loss: -57.9950 - acc: 0.0000e+00     \n",
      "Epoch 2/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 3/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 4/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 5/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 6/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 7/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 8/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 9/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 10/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 11/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 12/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 13/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 14/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 15/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 16/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 17/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 18/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 19/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 20/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 21/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 22/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 23/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 24/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 25/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 26/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 27/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 28/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 29/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 30/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 31/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 32/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 33/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 34/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 35/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 36/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 37/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 38/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 39/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 40/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 41/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 42/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 43/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 44/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 45/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 46/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 47/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 48/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 49/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 50/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 51/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 52/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 53/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 54/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 55/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 56/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 57/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 58/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 59/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 60/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 61/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 62/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 63/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 64/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 65/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 66/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 67/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 68/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 69/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 70/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 71/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 72/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 73/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 74/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 75/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 76/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 77/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 78/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 79/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 80/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 81/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 82/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 83/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 84/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 85/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 86/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 87/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 88/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 89/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 90/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 91/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 92/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 93/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 94/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 95/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 96/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 97/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 98/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 99/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 100/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 101/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 102/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 103/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 104/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 105/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 106/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 107/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 108/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 109/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 110/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 111/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 112/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 113/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 114/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 115/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 116/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 117/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 118/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 119/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 120/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 121/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 122/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 123/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 124/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 125/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 126/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 127/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 128/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 129/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 130/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 131/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 132/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 133/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 134/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 135/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 136/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 137/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 138/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 139/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 140/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 141/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 142/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 143/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 144/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 145/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 146/150\n",
      "18211/18211 [==============================] - 5s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 147/150\n",
      "18211/18211 [==============================] - 6s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 148/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 149/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n",
      "Epoch 150/150\n",
      "18211/18211 [==============================] - 7s - loss: -62.3075 - acc: 0.0000e+00     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b0a2cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, y_train, nb_epoch=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680/7805 [============================>.] - ETA: 0sacc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.663\n",
      "Model:                            OLS   Adj. R-squared:                  0.662\n",
      "Method:                 Least Squares   F-statistic:                     360.7\n",
      "Date:                Tue, 06 Dec 2016   Prob (F-statistic):               0.00\n",
      "Time:                        14:30:08   Log-Likelihood:                -7679.2\n",
      "No. Observations:               18211   AIC:                         1.556e+04\n",
      "Df Residuals:                   18111   BIC:                         1.634e+04\n",
      "Df Model:                          99                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const       -333.9286     28.662    -11.651      0.000      -390.108  -277.749\n",
      "x1            -4.2817      0.408    -10.492      0.000        -5.082    -3.482\n",
      "x2            -4.4259      0.394    -11.229      0.000        -5.199    -3.653\n",
      "x3            -4.3037      0.398    -10.819      0.000        -5.083    -3.524\n",
      "x4            -4.3494      0.405    -10.739      0.000        -5.143    -3.556\n",
      "x5            -4.3339      0.401    -10.812      0.000        -5.120    -3.548\n",
      "x6            -4.2506      0.406    -10.474      0.000        -5.046    -3.455\n",
      "x7            -4.3924      0.393    -11.167      0.000        -5.163    -3.621\n",
      "x8            -4.2829      0.399    -10.722      0.000        -5.066    -3.500\n",
      "x9            -4.3234      0.407    -10.618      0.000        -5.121    -3.525\n",
      "x10           -4.2597      0.401    -10.619      0.000        -5.046    -3.473\n",
      "x11           -4.2705      0.401    -10.638      0.000        -5.057    -3.484\n",
      "x12           -4.2787      0.407    -10.515      0.000        -5.076    -3.481\n",
      "x13           -4.2606      0.399    -10.681      0.000        -5.042    -3.479\n",
      "x14           -4.2677      0.399    -10.686      0.000        -5.050    -3.485\n",
      "x15           -4.4188      0.409    -10.792      0.000        -5.221    -3.616\n",
      "x16           -4.4127      0.410    -10.758      0.000        -5.217    -3.609\n",
      "x17           -4.3842      0.399    -10.999      0.000        -5.166    -3.603\n",
      "x18           -4.2361      0.399    -10.624      0.000        -5.018    -3.455\n",
      "x19           -4.4609      0.412    -10.828      0.000        -5.268    -3.653\n",
      "x20           -4.4922      0.413    -10.885      0.000        -5.301    -3.683\n",
      "x21           -4.6506      0.414    -11.236      0.000        -5.462    -3.839\n",
      "x22           -4.7516      0.410    -11.579      0.000        -5.556    -3.947\n",
      "x23           -4.8540      0.412    -11.771      0.000        -5.662    -4.046\n",
      "x24           -4.3750      0.399    -10.975      0.000        -5.156    -3.594\n",
      "x25           -4.6996      0.402    -11.693      0.000        -5.487    -3.912\n",
      "x26           -4.9755      0.413    -12.041      0.000        -5.785    -4.166\n",
      "x27           -5.0582      0.418    -12.115      0.000        -5.877    -4.240\n",
      "x28           -5.0642      0.420    -12.066      0.000        -5.887    -4.242\n",
      "x29           -5.0944      0.424    -12.027      0.000        -5.925    -4.264\n",
      "x30           -5.1530      0.426    -12.088      0.000        -5.988    -4.317\n",
      "x31           -4.7568      0.403    -11.794      0.000        -5.547    -3.966\n",
      "x32           -4.4001      0.411    -10.713      0.000        -5.205    -3.595\n",
      "x33           -4.7537      0.410    -11.605      0.000        -5.557    -3.951\n",
      "x34           -4.3417      0.400    -10.855      0.000        -5.126    -3.558\n",
      "x35           -4.9533      0.416    -11.903      0.000        -5.769    -4.138\n",
      "x36           -5.1358      0.425    -12.083      0.000        -5.969    -4.303\n",
      "x37           -4.3102      0.399    -10.801      0.000        -5.092    -3.528\n",
      "x38           -4.4213      0.398    -11.097      0.000        -5.202    -3.640\n",
      "x39           -4.3943      0.400    -10.998      0.000        -5.177    -3.611\n",
      "x40           -4.2157      0.407    -10.361      0.000        -5.013    -3.418\n",
      "x41           -5.1578      0.424    -12.176      0.000        -5.988    -4.327\n",
      "x42           -4.5454      0.385    -11.806      0.000        -5.300    -3.791\n",
      "x43           -4.5675      0.385    -11.876      0.000        -5.321    -3.814\n",
      "x44           -4.5581      0.377    -12.077      0.000        -5.298    -3.818\n",
      "x45           -4.5811      0.374    -12.242      0.000        -5.315    -3.848\n",
      "x46           -4.7286      0.381    -12.395      0.000        -5.476    -3.981\n",
      "x47           -4.6603      0.383    -12.156      0.000        -5.412    -3.909\n",
      "x48           -4.3412      0.387    -11.232      0.000        -5.099    -3.584\n",
      "x49           -4.4330      0.375    -11.835      0.000        -5.167    -3.699\n",
      "x50           -4.4944      0.367    -12.261      0.000        -5.213    -3.776\n",
      "x51           -4.5574      0.346    -13.166      0.000        -5.236    -3.879\n",
      "x52           -4.7538      0.390    -12.193      0.000        -5.518    -3.990\n",
      "x53           -4.2881      0.353    -12.138      0.000        -4.981    -3.596\n",
      "x54           -4.3383      0.376    -11.529      0.000        -5.076    -3.601\n",
      "x55           -4.4815      0.356    -12.572      0.000        -5.180    -3.783\n",
      "x56           -4.4038      0.376    -11.717      0.000        -5.141    -3.667\n",
      "x57           -4.5018      0.363    -12.392      0.000        -5.214    -3.790\n",
      "x58           -4.3660      0.378    -11.544      0.000        -5.107    -3.625\n",
      "x59           -4.5063      0.366    -12.314      0.000        -5.224    -3.789\n",
      "x60           -4.7682      0.385    -12.396      0.000        -5.522    -4.014\n",
      "x61           -4.5211      0.357    -12.675      0.000        -5.220    -3.822\n",
      "x62           -4.4572      0.380    -11.718      0.000        -5.203    -3.712\n",
      "x63           -4.4706      0.361    -12.380      0.000        -5.178    -3.763\n",
      "x64           -4.4743      0.358    -12.495      0.000        -5.176    -3.772\n",
      "x65           -4.3556      0.358    -12.165      0.000        -5.057    -3.654\n",
      "x66           -4.4381      0.388    -11.450      0.000        -5.198    -3.678\n",
      "x67           -4.4729      0.353    -12.679      0.000        -5.164    -3.781\n",
      "x68           -4.4453      0.357    -12.463      0.000        -5.144    -3.746\n",
      "x69           -4.3951      0.370    -11.892      0.000        -5.120    -3.671\n",
      "x70           -4.3135      0.381    -11.322      0.000        -5.060    -3.567\n",
      "x71           -4.3985      0.363    -12.133      0.000        -5.109    -3.688\n",
      "x72           -4.1155      0.333    -12.359      0.000        -4.768    -3.463\n",
      "x73           -4.5748      0.369    -12.412      0.000        -5.297    -3.852\n",
      "x74           -4.4186      0.352    -12.555      0.000        -5.108    -3.729\n",
      "x75          -55.7011      4.777    -11.661      0.000       -65.064   -46.338\n",
      "x76          -55.6269      4.776    -11.647      0.000       -64.989   -46.265\n",
      "x77          -55.5663      4.777    -11.632      0.000       -64.930   -46.203\n",
      "x78          -55.5236      4.777    -11.623      0.000       -64.887   -46.160\n",
      "x79          -55.9802      4.778    -11.716      0.000       -65.346   -46.614\n",
      "x80          -55.5305      4.777    -11.624      0.000       -64.895   -46.166\n",
      "x81         -110.9112      9.554    -11.609      0.000      -129.638   -92.184\n",
      "x82         -111.3863      9.554    -11.659      0.000      -130.113   -92.660\n",
      "x83         -111.6311      9.554    -11.685      0.000      -130.357   -92.905\n",
      "x84          -66.7682      5.732    -11.648      0.000       -78.004   -55.532\n",
      "x85          -66.8615      5.732    -11.665      0.000       -78.097   -55.626\n",
      "x86          -66.7770      5.732    -11.649      0.000       -78.013   -55.541\n",
      "x87          -66.7369      5.732    -11.642      0.000       -77.973   -55.501\n",
      "x88          -66.7851      5.733    -11.650      0.000       -78.022   -55.548\n",
      "x89            4.1191      0.622      6.618      0.000         2.899     5.339\n",
      "x90           -5.5154      0.543    -10.164      0.000        -6.579    -4.452\n",
      "x91            0.0726      0.003     24.734      0.000         0.067     0.078\n",
      "x92            0.1785      0.009     20.068      0.000         0.161     0.196\n",
      "x93            0.2102      0.006     36.920      0.000         0.199     0.221\n",
      "x94           -0.0415      0.004     -9.277      0.000        -0.050    -0.033\n",
      "x95           -0.0027      0.000    -18.040      0.000        -0.003    -0.002\n",
      "x96            0.0042      0.001      5.999      0.000         0.003     0.006\n",
      "x97            0.0077      0.005      1.476      0.140        -0.003     0.018\n",
      "x98            0.0342      0.004      8.683      0.000         0.026     0.042\n",
      "x99            0.0119      0.006      2.158      0.031         0.001     0.023\n",
      "x100           0.0130      0.006      2.060      0.039         0.001     0.025\n",
      "x101           0.0029      0.004      0.672      0.502        -0.006     0.012\n",
      "x102          -0.0476      0.005     -8.939      0.000        -0.058    -0.037\n",
      "x103          -0.0144      0.001    -11.047      0.000        -0.017    -0.012\n",
      "==============================================================================\n",
      "Omnibus:                     5606.231   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46499.587\n",
      "Skew:                           1.245   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.421   Cond. No.                     5.67e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.24e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#OLS\n",
    "X = sm.add_constant(x_train)\n",
    "model = sm.OLS(y_train,X)\n",
    "results = model.fit()\n",
    "print results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R square is 0.284.  There are some strong multicollinearity problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.663484435695\n",
      "Test Score 0.659456995631\n"
     ]
    }
   ],
   "source": [
    "#same OLS model with sklearn (easier to score but less detailed output)\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print \"Train Score\", model.score(x_train, y_train)\n",
    "print \"Test Score\", model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, for this split the test set does better than the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.663 Test 0.659\n",
      "Train 0.660 Test 0.668\n",
      "Train 0.658 Test 0.672\n",
      "Train 0.658 Test 0.673\n",
      "Train 0.657 Test 0.677\n",
      "Train 0.667 Test 0.652\n",
      "Train 0.664 Test 0.659\n",
      "Train 0.666 Test 0.655\n",
      "Train 0.662 Test 0.663\n",
      "Train 0.667 Test 0.652\n"
     ]
    }
   ],
   "source": [
    "#try several random seeds to check for stability and variance\n",
    "for r in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_log, test_size=0.3, random_state=r)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    print \"Train {:.3f} Test {:.3f}\".format(model.score(x_train, y_train), model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.41440325e-01,   7.04484144e-02,   2.11267244e-01,\n",
       "         4.50986058e-02,   1.96923704e-01,   2.00466488e-01,\n",
       "         1.08696323e-01,   2.58744032e-01,   2.21433681e-01,\n",
       "         2.50390305e-01,   2.43440383e-01,   2.59369151e-01,\n",
       "         2.93402077e-01,   2.72060093e-01,   9.01109517e-02,\n",
       "         1.48403458e-01,   1.59642368e-01,   2.86570058e-01,\n",
       "         8.88843631e-02,   4.02769837e-02,  -1.02441676e-01,\n",
       "        -1.77450213e-01,  -3.12881039e-01,   1.56151409e-01,\n",
       "        -1.37155564e-01,  -3.71559823e-01,  -4.62448875e-01,\n",
       "        -4.48144358e-01,  -4.89418607e-01,  -5.59794254e-01,\n",
       "        -2.19996118e-01,   1.72229713e-01,  -1.19633077e-01,\n",
       "         1.85396913e-01,  -4.42381403e-01,  -5.37627062e-01,\n",
       "         2.11636012e-01,   1.28757120e-01,   1.59110432e-01,\n",
       "         2.72530082e-01,  -6.93481277e-01,  -1.00227013e-03,\n",
       "        -6.21626831e-02,  -3.24971783e-02,  -6.18589978e-02,\n",
       "        -1.56424267e-01,  -1.11979742e-01,   1.67779700e-01,\n",
       "         1.88898556e-02,   8.17225782e-03,  -5.78924432e-02,\n",
       "        -3.91249376e-01,   1.42319501e-01,   1.55198733e-01,\n",
       "         2.95980819e-02,   4.98554350e-02,  -2.96597696e-02,\n",
       "         1.12155474e-01,  -5.45068912e-02,  -3.30511194e-01,\n",
       "        -5.13794621e-02,   4.66230608e-02,  -3.14396786e-02,\n",
       "        -5.18983968e-02,   4.15625514e-02,   2.86302973e-03,\n",
       "        -3.44225681e-02,   1.08034361e-02,   7.18758404e-02,\n",
       "         1.83023664e-01,   1.17686947e-01,   4.11199427e-01,\n",
       "        -4.85227105e-02,   3.93332907e-02,  -5.17460898e-02,\n",
       "         1.72532926e-02,   8.26739114e-02,   1.11362535e-01,\n",
       "        -3.23691899e-01,   1.64148250e-01,   4.01551762e-01,\n",
       "        -6.50215185e-02,  -3.36530243e-01,   2.22036217e-02,\n",
       "        -6.11036308e-02,  -1.03651223e-02,   1.69576780e-02,\n",
       "         3.23074534e-02,   3.26685004e+00,  -5.27289443e+00,\n",
       "         8.03700540e-02,   1.60943661e-01,   2.11743527e-01,\n",
       "        -4.84683409e-02,  -2.72892157e-03,   4.13081607e-03,\n",
       "         1.44205706e-02,   2.89216736e-02,   1.75131773e-02,\n",
       "         7.68457546e-03,   5.89752581e-03,  -5.19469578e-02,\n",
       "        -1.34952839e-02])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We check that the coefficients are reasonable (similar in magnitude).  Before we discarded the zipcodes with only a small number of data points, we observed high variance and numerical instability in the coefficents."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
